{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Instructions To Reproduce this Data Cleaning Notebook:\n",
    "(Step 1 Optional)\n",
    "1. Create a virtual python environment in the project directory (if you want) for all of the packages required:  \n",
    "``` \n",
    "python -m venv .venv\n",
    "```\n",
    "To enter the virutal environment: \n",
    "```\n",
    ".venv/Scripts/activate.ps1 # on windows\n",
    "source .venv/bin/activate # on mac/linux\n",
    "```\n",
    "2. Download all of the required packages (run in cmd/shell of choice):\n",
    "```\n",
    "pip install pandas\n",
    "pip install numpy\n",
    "```\n",
    "3. VSCode: Ensure you have the correct python kernel selected!\n",
    "<br> \n",
    "If you are using a virtual environment, make sure to select the python interpreter for that virtual environment otherwise this will not work! If you have everything done globally, then just make sure the correct python kernel you are using is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/CLFrod/Assignment2CSI4142/refs/heads/master/StudentsPerformance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset 2: \"Students performance in Exams\"</h1>\n",
    "<h3>Task: Data Imputation</h3>\n",
    "\n",
    "Author: Jakki Seshapanpu\n",
    "\n",
    "\"This data set consists of the marks secured by [US high school] students in various subjects...To understand the influence of the parents background, test preparation etc on students performance\"\n",
    "\n",
    "<h3>Dataset Specifications & Features</h3>\n",
    "\n",
    "The dataset has 8 columns and 1000 rows.\n",
    "\n",
    "Link: <a href=\"https://www.kaggle.com/datasets/spscientist/students-performance-in-exams/data\">Students Performance in Exams</a>\n",
    "\n",
    "### Feature List\n",
    "#### Gender\n",
    "Categorical - Nominal\n",
    "<br>\n",
    "Male/Female\n",
    "#### Race/Ethnicity\n",
    "Categorical - Nominal\n",
    "<br>\n",
    "Referred to as groups ranging from A-E\n",
    "#### Parental Level of Education\n",
    "Categorical - Ordinal\n",
    "<br>\n",
    "Level of education of the student's parents.\n",
    "<br>\n",
    "Arguably, this data type could be nominal. I chose ordinal because there is a discernable difference in level one can make across the diploma types.\n",
    "#### Lunch\n",
    "Categorical - Nominal\n",
    "<br>\n",
    "The type of lunch plan the student is paying for.\n",
    "#### Test Preparation Course\n",
    "Categorical - Nominal\n",
    "<br>\n",
    "If the student had taken the course to prepare for the test or not\n",
    "#### Math Score\n",
    "Numerical - Discrete\n",
    "#### Reading Score\n",
    "Numerical - Discrete\n",
    "#### Writing Score\n",
    "Numerical - Discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Test #1\n",
    "We will simulate \"Missing Completely At Random\"-type missing values.\n",
    "<br>\n",
    "For this, the 'gender' column will be used.\n",
    "<br>\n",
    "We can randomly delete entries in the column amounting to a fraction of the total data.\n",
    "<br>\n",
    "Then, we will use Random Sample Imputation to re-fill the empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between D1 and D2: 75.6%\n"
     ]
    }
   ],
   "source": [
    "# Make 2 copies of the 'gender' column\n",
    "D1 = data['gender'].copy()\n",
    "D2 = data['gender'].copy()\n",
    "\n",
    "# Calculate the number of entries to drop\n",
    "drop = 0.50 # a simulated percentage\n",
    "num_to_drop = int(len(D2) * drop)\n",
    "\n",
    "# Randomly select entries to drop\n",
    "np.random.seed(0)  # for reproducibility. comment out for multiple tries\n",
    "drop_indices = np.random.choice(D2.index, num_to_drop, replace=False)\n",
    "D2.loc[drop_indices] = np.nan\n",
    "\n",
    "# Fill empty entries in D2 with random samples from D1\n",
    "missing = D2.isnull()\n",
    "num_missing = missing.sum()\n",
    "if num_missing > 0:\n",
    "    sampled_values = D1.dropna().sample(num_missing, replace=True).values\n",
    "    D2.loc[missing] = sampled_values\n",
    "\n",
    "# Compare D1 to D2 in similarity\n",
    "similarity = (D1 == D2).mean()\n",
    "print(f\"Similarity between D1 and D2: {similarity * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Results and Discussion\n",
    "D1-D2 similarity with Random Sample Imputation Accuracy and random seed 0:\n",
    "<br>\n",
    "Format: **drop percentage : D1-D2 similarity percentage : accuracy rating**\n",
    "<br>\n",
    "5% : 96.5% : 30%\n",
    "<br>\n",
    "10% : 95.1% : 51%\n",
    "<br>\n",
    "15% : 93% : 53%\n",
    "<br>\n",
    "20% : 89.9% : 50%\n",
    "<br>\n",
    "33% : 83.8% : 54%\n",
    "<br>\n",
    "50% : 75.6% : 51%\n",
    "<br>\n",
    "For this column, where the types of entries are split close to 50/50, Random Sample Imputation is not very effective in recreating the original entries, with an average accuracy rating of about 50%. Furthermore, I would say that as the types of entries increases past 2, this imputation's effectiveness in finding the correct missing values decreases. Generally, this imputation would be fine if wanting to recreate the proportional amounts of each type of entry, but is ineffective in confidently replicating the original value of the data cell. It is only moderately effective in this case because the chance of error is minimized with there only being Male or Female as entries - which is why I chose it for this experiment. Only accuracy was calculated because precision and recall are trivial for this column's values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Test #2\n",
    "We will simulate \"Missing At Random\"-type missing values.\n",
    "For this, the 'reading score' will be the target for bivariate imputation, with 'writing score' serving as a contextual variable to predict from. In this situation, reading score data is more likely to be missing for those who scored low on the writing score.\n",
    "<br>\n",
    "We'll randomly delete entries in reading score where the writing score is on the lower end (\\<50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               math score  reading score  writing score\n",
      "math score       1.000000       0.817580       0.802642\n",
      "reading score    0.817580       1.000000       0.954598\n",
      "writing score    0.802642       0.954598       1.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data[['math score', 'reading score', 'writing score']].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         count       mean        std   min   25%   50%   75%  \\\n",
      "test preparation course                                                        \n",
      "completed                358.0  74.418994  13.375335  36.0  66.0  76.0  83.0   \n",
      "none                     642.0  64.504673  14.999661  10.0  54.0  65.0  74.0   \n",
      "\n",
      "                           max  \n",
      "test preparation course         \n",
      "completed                100.0  \n",
      "none                     100.0  \n"
     ]
    }
   ],
   "source": [
    "# Group by 'test preparation course' and describe 'writing score'\n",
    "math_scores_description = data.groupby('test preparation course')['writing score'].describe()\n",
    "print(math_scores_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Test #3\n",
    "We will simulate \"Missing Not At Random\"-type missing values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
